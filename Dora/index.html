<!DOCTYPE html>
<head>
    <meta charset="utf-8" />
    <title>Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders</title>
	<link rel="icon" type="image/x-icon" href="../assets/css/images/favicon.ico">
    <meta content="Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <script type="text/javascript" src="static/js/zoom.js"></script>
    <script type="text/javascript" src="static/js/video_comparison.js"></script>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MLDP9MKGC8"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-MLDP9MKGC8');
    </script>
    <script type="module" src="static/js/model-viewer.min.js"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
</head>

<body>
    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders</h1>
            <!-- <div class="nerf_subheader_v2"></div> -->
            <div class="nerf_subheader_v2">
                <div>
                    <a href="https://aruichen.github.io/" target="_blank" class="nerf_authors_v2">Rui Chen<span
                            class="text-span_nerf"></span></a><sup>1,2</sup>,&nbsp;&nbsp;
                    <a href="http://jeff95.me/" target="_blank" class="nerf_authors_v2">Jianfeng Zhang<span
                            class="text-span_nerf"></span></a><sup>2*</sup>,&nbsp;&nbsp;
                    <a href="https://yixunliang.github.io/" target="_blank" class="nerf_authors_v2">Yixun Liang<span
                            class="text-span_nerf"></span></a><sup>1,3</sup>,&nbsp;&nbsp;
                    <a href="https://logan0601.github.io/" target="_blank" class="nerf_authors_v2">Guan Luo<span
                            class="text-span_nerf"></span></a><sup>2,4</sup>,&nbsp;&nbsp;
                    <a href="https://weiyuli.xyz/" target="_blank" class="nerf_authors_v2">Weiyu Li<span
                        class="text-span_nerf"></span></a><sup>1,3</sup>,&nbsp;&nbsp;
                    <h1 class="nerf_affiliation_v2">Jiarui Liu</h1><sup>1,3</sup>
                </div> 
                    <a href="https://lixiulive.com/" target="_blank" class="nerf_authors_v2">Xiu Li<span
                        class="text-span_nerf"></span></a><sup>2</sup>,&nbsp;&nbsp;
                    <a href="https://www.xxlong.site/" target="_blank" class="nerf_authors_v2">Xiaoxiao Long<span
                        class="text-span_nerf"></span></a><sup>1,3</sup>,&nbsp;&nbsp;
                    <a href="https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&hl=en" target="_blank" class="nerf_authors_v2">Jiashi Feng<span
                        class="text-span_nerf"></span></a><sup>2</sup>,&nbsp;&nbsp;
                    <a href="https://ece.hkust.edu.hk/pingtan" target="_blank" class="nerf_authors_v2">Ping Tan<span
                            class="text-span_nerf"></span></a><sup>1,3*</sup>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>*</sup>Corresponding authors</h1>
                </div>
                <div>
                    <h1 class="nerf_affiliation_v2"><sup>1 </sup>The Hong Kong University of Science and Technology</h1>
                    <h1 class="nerf_affiliation_v2"><sup>2 </sup>Bytedance Seed</h1>
                    <h1 class="nerf_affiliation_v2"><sup>3 </sup>LightIllusions</h1>
                    <h1 class="nerf_affiliation_v2"><sup>4 </sup>Tsinghua University</h1>
                </div>

                <div class="external-link">
                    <a class="btn" href="https://github.com/Seed3D/Dora" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-github"></i> Code (coming)</a>
                    <a class="btn" href="https://arxiv.org/pdf/2412.17808" role="button" target="_blank">
                        <i class="ai ai-arxiv"></i> Arxiv </a>
                    <a class="btn btn-large btn-light" href="https://www.youtube.com/watch?v=6evNqk0b-bQ" role="button" target="_blank" disabled>
                        <i class="fa-brands fa-youtube"></i> Video </a>
                </div>
                
            </div>
        </div>
    </div>

    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                Recent 3D content generation pipelines commonly employ Variational Autoencoders (VAEs) to encode shapes into compact latent representations for diffusion-based generation. However, the widely adopted uniform point sampling strategy in Shape VAE training often leads to a significant loss of geometric details,  limiting the quality of shape reconstruction and downstream generation tasks.
                We present Dora-VAE, a novel approach that enhances VAE reconstruction through our proposed sharp edge sampling strategy and a dual cross-attention mechanism. By identifying and prioritizing regions with high geometric complexity during training, our method significantly improves the preservation of fine-grained shape features. Such sampling strategy and the dual attention mechanism enable the VAE to focus on crucial geometric details that are typically missed by uniform sampling approaches.
                To systematically evaluate VAE reconstruction quality, we additionally propose Dora-bench, a benchmark that quantifies shape complexity through the density of sharp edges, introducing a new metric focused on reconstruction accuracy at these salient geometric features. Extensive experiments on the Dora-bench demonstrate that Dora-VAE achieves comparable reconstruction quality to the state-of-the-art dense XCube-VAE while requiring a latent space at least 8x smaller (1,280 vs. > 10,000 codes).
                <br>
            </p>
        </div>
    </div>
    
    <!-- Paper video. -->
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Video</h2>
        <div class="publication-video">
        <iframe src="https://www.youtube.com/embed/6evNqk0b-bQ?rel=0&amp;modestbranding=1"
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
    </div>
        <!--/ Paper video. -->
    <!-- <hr> -->
    
    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">The reconstructed results of Dora-VAE in Dora-bench 
            <span style="color: red; font-size: small;">(Point clouds are interactable)</span>
        </h2>
        <button onclick="document.querySelectorAll('video').forEach(video => video.playbackRate = 0)">0x</button>
        <button onclick="document.querySelectorAll('video').forEach(video => video.playbackRate = 0.5)">0.5x</button>
        <button onclick="document.querySelectorAll('video').forEach(video => video.playbackRate = 1)">1x</button>
        <button onclick="document.querySelectorAll('video').forEach(video => video.playbackRate = 1.5)">1.5x</button>
        <button onclick="document.querySelectorAll('video').forEach(video => video.playbackRate = 2)">2x</button>
        <div class="grid-container-4">
            <div>
                <p class="myprompt nerf_text">GT geometry</p>
                <video class="video" loop playsinline autoPlay muted 
                src="assets/reconstruction/teaser1.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
            <div>
                <p class="myprompt nerf_text">Reconstructed geometry (ours)</p>
                <video class="video" loop playsinline autoPlay muted 
                src="assets/reconstruction/teaser1_recon.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
            <div>
                <p class="myprompt nerf_text">Sharp edge sampling (ours)</p>
                <iframe src="other_html/vae_reconstruction/teaser1-SES_PLY.html"></iframe>
            </div>
            <div>
                <p class="myprompt nerf_text">Uniform sampling</p>
                <iframe src="other_html/vae_reconstruction/teaser1-Uniform_PLY.html"></iframe>
            </div>
        </div>
        <div class="grid-container-1">
            <a class="mybtn" href="reconstruction-gallery_0.html" role="button">
             More Results </a>
        </div>
    </div>


    <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Image to 3D</h2>
        <div class="grid-container-4">
            <img  src="assets/image_to_3d/9.png" width="230" height="230">
            <div>
                <video class="video" loop playsinline autoPlay muted 
                src="assets/image_to_3d/9.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
            <img  src="assets/image_to_3d/50.png" width="230" height="230">
            <div>
                <video class="video" loop playsinline autoPlay muted 
                src="assets/image_to_3d/50.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
        </div>

        <div class="grid-container-1">
            <a class="mybtn" href="image_3d-gallery_0.html" role="button">
            More Results </a>
        </div>

        <div class="grid-container-1">
            <h2 class="grey-heading_nerf">character control</h2>
            <div>
                <video class="video" loop playsinline autoPlay muted 
                src="assets/images/character_control.mp4" onplay="resizeAndPlay(this)"></video>
            </div>
            <p class="paragraph-3 nerf_text nerf_results_text">
                The 3D asset generated by our model is ready for diffusion-based character control in modern 3D engines, such as Unity 3D, in real-time.
                <br>
            </p>
        </div>
    </div>

    <!-- <div class="white_section_nerf  w-container">
        
    </div> -->

    <div class="white_section_nerf  w-container">
        <h2 class="center_text">Method</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            We present Dora-VAE for high-quality 3D reconstruction, and Dora-Bench for 3D VAE evaluation.  
            The improved reconstruction quality offered by Dora-VAE can directly boost the performance ceiling 
            of diffusion models, enabling higher-quality generation results under the same training conditions.
            <br>
        </p>
        </p>
       

        <!-- <img src="assets/images/Dora-VAE_pipeline.png" width=50% height=50%/> -->
        <div class="grid-container-1">
            <h2 class="grey-heading_nerf">Dora-VAE</h2>
            <div style="text-align: center;">
                <img src="assets/images/Dora-VAE_pipeline.png" style="width: 50%; height: auto;" />
            </div>
            <p class="paragraph-3 nerf_text nerf_results_text">
                For each input mesh, we augment the uniformly sampled point cloud Pu 
                with more important points Pa sampled by our proposed sharp edge sampling strategy, 
                which forms the dense point cloud Pd. During the encoding process, we compute the attention 
                for Pu and Pa separately via a simple-yet-effective dual cross-attention mechanism and 
                sum the results for self-attention to compute the latent code z.
                <br>
            </p>
        </div>
        <div class="grid-container-1">
            <h2 class="grey-heading_nerf">Dora-bench</h2>
            <div style="text-align: center;">
                <img src="assets/images/Dora-bench_pipeline.png" style="width: 50%; height: auto;" />
            </div>
            <p class="paragraph-3 nerf_text nerf_results_text">
                To enable more rigorous evaluation of VAE performance, we propose Dora-bench, 
                a benchmark that systematically categorizes test shapes based on their geometric complexity.
                Unlike previous methods that use randomly selected test sets, 
                we measure shape complexity using the number of salient edges
                and classify shapes into four levels. We curate test shapes from multiple public datasets 
                including GSO,  ABO,  Meta, and  Objaverse test sets to ensure diverse geometric complexities. 
                <br>
            </p>
        </div>
    </div>


    <!-- <div class="white_section_nerf  w-container">
        <h2 class="grey-heading_nerf">Related Works</h2>
        <div class="grid-container-1">
	    <p> 
		    <a href="https://neuralcarver.github.io/michelangelo/" target="_blank">Michelangelo</span></a>: 
a Shape-Image-Text-Aligned 3D Variational Auto-Encoder (SITA-VAE) and a conditional Aligned 3D Shape Latent Diffusion Model (ASLDM). Thanks for their open source;<br>
	    	    <a href="https://github.com/CLAY-3D/OpenCLAY" target="_blank">OpenCLAY</a>:
a large-scale generative model composed of a multi-resolution 3D Variational Autoencoder (VAE) and a minimalistic latent 3D Diffusion Transformer (DiT);<br>
		    <a href="https://nju-3dv.github.io/projects/Direct3D/" target="_blank">Direct3D</a>:
a Direct 3D Variational Auto-Encoder (D3D-VAE) and a Direct 3D Diffusion Transformer (D3D-DiT) scalable to in-the-wild input single view images;
	    </p>
        </div>
    </div> -->

<div class="white_section_nerf grey_container w-container">
<h2 class="grey-heading_nerf">BibTeX</h2>
<div class="bibtex">
    <pre><code>@article{chen2024dora,
        title={Dora: Sampling and Benchmarking for 3D Shape Variational Auto-Encoders}, 
        author={Rui Chen and Jianfeng Zhang and Yixun Liang and Guan Luo and Weiyu Li and Jiarui Liu and Xiu Li and Xiaoxiao Long and Jiashi Feng and Ping Tan},
        journal={arXiv preprint arXiv:2412.17808},
        year={2024},
  }</code></pre>
</div>
</div>

</body>
<footer>
    The code of <a href="https://github.com/ARuiChen/ARuiChen.github.io">this</a> project page is modified from <a href="https://github.com/Craftsman3D/Craftsman3D.github.io">Craftsman3D</a>.
</footer>

</html>
