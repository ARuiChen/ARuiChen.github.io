<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title> Rui Chen  </title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="A2nXUugMvMH5Xy0yLCrnLyU0jySYHhQGTZwju8WLFCk" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
  <link rel="dns-prefetch" href="https://fonts.gstatic.com">
  <link rel="dns-prefetch" href="https://www.google-analytics.com">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Chen </name>  <br> <br>
              </p>
              <p style="font-family:verdana"> Rui Chen is a first-year graduate student at the South China University of Technology, working under the guidance of Prof. <a href="http://kuijia.site/">Kui Jia</a>. 
                My research focuses on the combination of computer graphics and computer vision, specifically in the realm of creating high-quality 3D assets using generative models and physically-based rendering techniques. My email is riorui@foxmail.com. 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
             <img style="width:100%;max-width:100%" alt="profile photo" src="images/cr.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
         
        <h2>Reasearch</h2>
        <p class="w3-justify">
        </p>
            <p>
            <strong>Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation</strong><br>
            <strong href="https://aruichen.github.io/">Rui Chen*</strong>, <a>Yongwei Chen*</a>, <a href="https://ningxinj.github.io/">Ningxin Jiao</a>, <a href="http://kuijia.site/">Kui Jia</a><br>
            <em>ICCV2023</em> | <a style="color: #447ec9" href="https://arxiv.org/abs/2303.13873">Paper</a> | <a style="color: #447ec9" href="https://fantasia3d.github.io/">Project Page</a> | <a style="color: #447ec9" href="https://github.com/Gorilla-Lab-SCUT/Fantasia3D">Code</a> | <a style="color: #447ec9" href="https://www.youtube.com/watch?v=Xbzl4HzFiNo">Video</a> <br>
            <p style="text-align: center;"><img style="width:90%;" src="images/fantasia3D.jpg"></p>
            </p>
      
            <p>
            <strong>TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting Decomposition</strong><br>
            <a>Yongwei Chen</a>, <strong href="https://aruichen.github.io/">Rui Chen</strong>, <a href="https://jblei.site/">Jiabao Lei</a>, <a href="https://ybzh.github.io/">Yabin Zhang</a>, <a href="http://kuijia.site/">Kui Jia</a><br>
            <em>NeurIPS 2022 (spotlight)</em> | <a style="color: #447ec9" href="https://arxiv.org/abs/2210.11277">Paper</a> | <a style="color: #447ec9" href="https://cyw-3d.github.io/tango">Project Page</a> | <a style="color: #447ec9" href="https://github.com/Gorilla-Lab-SCUT/tango">Code</a><br>
            <p style="text-align: center;"><img style="width:90%;" src="images/neurips2022.jpg"></p>
            </p>                                                                                                                 
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tbody>
                  <tr>
                    <td>
                      <heading>News</heading>
                      <p>
                      <ul>
                        <li>News (Mar  2022): One paper accepted to CVPR 2022.</li>
                        
                      </ul>
                      </p>
                    </td>
                  </tr>
                </tbody>
        </tbody></table> -->
 	
	                                                                                                                               
      </td>
    </tr>
  </table>
</body>


  
</html>
